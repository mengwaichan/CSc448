{"cells":[{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-12-19T19:14:05.337029Z","iopub.status.busy":"2023-12-19T19:14:05.336669Z","iopub.status.idle":"2023-12-19T19:14:05.344332Z","shell.execute_reply":"2023-12-19T19:14:05.343436Z","shell.execute_reply.started":"2023-12-19T19:14:05.336995Z"}},"source":["---\n","\n","# Georgios_Ioannou\n"]},{"cell_type":"markdown","metadata":{},"source":["## Copyright Â© 2023 by Georgios Ioannou\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","<h1 align=\"center\"> Text Emotion System Sentiment Analysis </h1>\n","<h2 align=\"center\"> TESSA </h2>\n","\n","In this notebook, we will be classifying emotion based on text documents. The dataset we will be using is called:\n","\n","<p style=\"text-align: center;\"><a href=\"https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\">Emotions Dataset for NLP</a></p>\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","<h2 align=\"center\"> Remember our main steps motto \"ISBE\" </h2>\n","\n","<h3 align=\"center\"> Main Steps when building a Machine Learning Model </h3>\n","\n","1. **I** - `Inspect and explore data`\n","2. **S** - `Select and engineer features`\n","3. **B** - `Build and train model`\n","4. **E** - `Evaluate model`\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","<h2 align='center'> GPU Information </h2>\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T08:15:27.660014Z","iopub.status.busy":"2023-12-20T08:15:27.659641Z","iopub.status.idle":"2023-12-20T08:15:28.644849Z","shell.execute_reply":"2023-12-20T08:15:28.643753Z","shell.execute_reply.started":"2023-12-20T08:15:27.659979Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Dec 20 08:15:28 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","<h2 align='center'> Libraries </h2>\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T08:15:28.647602Z","iopub.status.busy":"2023-12-20T08:15:28.647274Z","iopub.status.idle":"2023-12-20T08:15:34.349236Z","shell.execute_reply":"2023-12-20T08:15:34.348325Z","shell.execute_reply.started":"2023-12-20T08:15:28.647575Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /kaggle/working/...\n","Archive:  /kaggle/working/corpora/wordnet.zip\n","   creating: /kaggle/working/corpora/wordnet/\n","  inflating: /kaggle/working/corpora/wordnet/lexnames  \n","  inflating: /kaggle/working/corpora/wordnet/data.verb  \n","  inflating: /kaggle/working/corpora/wordnet/index.adv  \n","  inflating: /kaggle/working/corpora/wordnet/adv.exc  \n","  inflating: /kaggle/working/corpora/wordnet/index.verb  \n","  inflating: /kaggle/working/corpora/wordnet/cntlist.rev  \n","  inflating: /kaggle/working/corpora/wordnet/data.adj  \n","  inflating: /kaggle/working/corpora/wordnet/index.adj  \n","  inflating: /kaggle/working/corpora/wordnet/LICENSE  \n","  inflating: /kaggle/working/corpora/wordnet/citation.bib  \n","  inflating: /kaggle/working/corpora/wordnet/noun.exc  \n","  inflating: /kaggle/working/corpora/wordnet/verb.exc  \n","  inflating: /kaggle/working/corpora/wordnet/README  \n","  inflating: /kaggle/working/corpora/wordnet/index.sense  \n","  inflating: /kaggle/working/corpora/wordnet/data.noun  \n","  inflating: /kaggle/working/corpora/wordnet/data.adv  \n","  inflating: /kaggle/working/corpora/wordnet/index.noun  \n","  inflating: /kaggle/working/corpora/wordnet/adj.exc  \n","[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Import libraries.\n","\n","# Use inline so our visualizations display in notebook.\n","\n","\n","%matplotlib inline\n","\n","\n","import matplotlib.pyplot as plt   # Data visualization.\n","import nltk                       # Natural Language Processing.\n","import numpy as np                # Data wrangling.\n","import os                         # Manipulate operating system interfaces.\n","import pandas as pd               # Data handling.\n","pd.set_option('display.max_colwidth', None)\n","import pickle                     # Python object serialization.\n","import plotly.express as px       # Data visualization\n","import plotly.graph_objects as go # Data visualization\n","import re                         # Regular expression operations.\n","import seaborn as sns             # Data visualization.\n","import subprocess                 # To download nltk wordnet in Kaggle.\n","sns.set()\n","import warnings                   # Ignore all warnings.\n","warnings.filterwarnings('ignore')\n","\n","\n","from nltk.stem import WordNetLemmatizer # Lemmatize using WordNet's built-in morphy function.\n","from nltk.stem import PorterStemmer     # Remove morphological affixes from words, leaving only the word stem.\n","from nltk.corpus import stopwords       # Remove stopwaords.\n","from nltk import word_tokenize          # Tokenize.\n","from sklearn.feature_extraction.text import CountVectorizer # Convert a collection of text documents to a matrix of token counts.\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, multilabel_confusion_matrix, precision_score, recall_score # Evaluation metrics.\n","from sklearn.model_selection import train_test_split     # Eplit data in training/validating/testing.\n","from sklearn.naive_bayes import MultinomialNB            # Multinomial Naive Bayes classifier.\n","from sklearn.preprocessing import LabelEncoder           # Encode target labels with value between 0 and n_classes-1.\n","from tensorflow.keras.callbacks import EarlyStopping     # Stop training when a monitored metric has stopped improving.\n","from tensorflow.keras.callbacks import ReduceLROnPlateau # Reduce learning rate when a metric has stopped improving.\n","from tensorflow.keras.layers import Activation, BatchNormalization, Bidirectional, Concatenate, Conv1D, Dense, Dropout, Embedding, GlobalMaxPooling1D, LSTM, MaxPooling1D, ReLU # Keras layers API.\n","from tensorflow.keras.models import Model, Sequential # Model achitecture.\n","from tensorflow.keras.optimizers import Adam         # Adam optimizer.\n","from tensorflow.keras.preprocessing.sequence import pad_sequences # Transformsa list of sequences into a 2D Numpy array.\n","from tensorflow.keras.preprocessing.text import Tokenizer         # Vectorize a text corpus.\n","from tensorflow.keras.utils import plot_model                     # Visualize the model and save it.\n","from tensorflow.keras.utils import to_categorical                 # Converts a class vector (integers) to binary class matrix.\n","\n","\n","try:\n","    nltk.data.find('wordnet.zip')\n","except:\n","    nltk.download('wordnet', download_dir='/kaggle/working/')\n","    command = 'unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora'\n","    subprocess.run(command.split())\n","    nltk.data.path.append('/kaggle/working/')\n","    \n","\n","from nltk.corpus import wordnet\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","## #3 Build And Train Multinomial Naive Bayes Model\n"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T08:29:07.121470Z","iopub.status.busy":"2023-12-20T08:29:07.120854Z","iopub.status.idle":"2023-12-20T08:29:07.664720Z","shell.execute_reply":"2023-12-20T08:29:07.663891Z","shell.execute_reply.started":"2023-12-20T08:29:07.121434Z"},"trusted":true},"outputs":[],"source":["# Split the data into train and test.\n","# Train: 90%\n","# Test: 10%\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.1, random_state=42\n",")\n","\n","# Initialize the vectorizer.\n","\n","vectorizer = CountVectorizer()\n","\n","# Create the vocabulary matrix.\n","\n","vectorizer.fit(X_train)\n","\n","# Transform the documents into vectors.\n","\n","X_train = vectorizer.transform(X_train)\n","X_test = vectorizer.transform(X_test)"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T08:29:07.666410Z","iopub.status.busy":"2023-12-20T08:29:07.665984Z","iopub.status.idle":"2023-12-20T08:29:07.772330Z","shell.execute_reply":"2023-12-20T08:29:07.771469Z","shell.execute_reply.started":"2023-12-20T08:29:07.666373Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"],"text/plain":["MultinomialNB()"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["# Initalize the model.\n","\n","model = MultinomialNB()\n","\n","# Fit the model with the training data.\n","\n","model.fit(X_train, y_train)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":605165,"sourceId":1085454,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
